
<div align="center">

# üçìüí• JPA <br> Jailbreaking Prompt Attack:<br> A Controllable Adversarial Attack <br> against Diffusion Models
</div>

Welcome to the official implementation of the paper: [Jailbreaking Prompt Attack: A Controllable Adversarial Attack against Diffusion Models](https://arxiv.org/abs/2404.02928). This work introduces one fast and efficient attack methods to generate toxic content for safety-driven diffusion models.
<table align="center">
  <tr>
    <td align="center"> 
      <embed src="https://github.com/mjc-ma/JPA/blob/main/imgs/main.pdf" width="1000" height="600" />
                 
      <br>
    </td>
  </tr>
</table>
<div align="left">

## Abstract 
Text-to-image (T2I) models can be maliciously used to generate harmful content such as sexually explicit, unfaithful, and misleading or Not-Safe-for-Work (NSFW) images. Previous attacks largely depend on the availability of the diffusion model or involve a lengthy optimization process. 
In this work, we investigate a more practical and universal attack that does not require the presence of a target model and demonstrate that the high-dimensional text embedding space inherently contains NSFW concepts that can be exploited to generate harmful images.  We present the \textbf{\underline{J}}ailbreaking \textbf{\underline{P}}rompt \textbf{\underline{A}}ttack (\textit{JPA}). \textit{JPA} first searches for the target malicious concepts in the text embedding space using a group of antonyms generated by ChatGPT. Subsequently, a prefix prompt is optimized in the discrete vocabulary space to align malicious concepts semantically in the text embedding space.We further introduce a soft assignment with gradient masking technique that allows us to perform gradient ascent in the discrete vocabulary space.
We perform extensive experiments with open-sourced T2I models, e.g.~\citep{stable-diffusion-v1-4} and closed-sourced online services, e.g. ~\citep{ramesh2022hierarchical,midjourney,podell2023sdxl}  with black-box safety checkers. Results show that (1) JPA bypasses both text and image safety checkers (2) while preserving high semantic alignment with the target prompt. (3) JPA demonstrates a much faster speed than previous methods and can be executed in a fully automated manner. These merits render it a valuable tool for robustness evaluation in future text-to-image generation research.

## Code Structure
```configs```: contains the default parameter for each methods

```prompts```: contains the prompts we selected for each experiments

```src```: contains the source code for the proposed methods

* ```attackers```: contains different attack methods (different discrete optimization methods)
* ```tasks```: contains different type of attacks (auxiliary model-based attacks P4D, and ours UnlearnDiff)
* ```execs```: contains the main execution files to run experiments
* ```loggers```: contains the logger codes for the experiments

## Usage
In this section, we provide the instructions to reproduce the results on nudity (ESD) in our paper. You can change the config file path to reproduce the results on other concepts or unlearned models.

### Requirements

```conda env create -n ldm --file environments/x86_64.yaml```

### Unlearned model preparation 
Here we provide different unlearned models from ESD and FMN. You can download them from [here](https://drive.google.com/file/d/1f4gncLqMXXdlbxpiFtY0WefDL1YUr9b7/view?usp=sharing). We also provide an Artist classifier for evaluating the style task. You can download it from [here](https://drive.google.com/file/d/1me_MOrXip1Xa-XaUrPZZY7i49pgFe1po/view?usp=share_link).

### Generate dataset

```python src/execs/generate_dataset.py --prompts_path prompts/nudity.csv --concept i2p_nude --save_path files/dataset```


### No attack

```python src/execs/attack.py --config-file configs/nudity/no_attack_esd_nudity_classifier.json --attacker.attack_idx $i --logger.name attack_idx_$i```

where ```i``` is from ```[0,142)```

### UnlearnDiff attack

```python src/execs/attack.py --config-file configs/nudity/text_grad_esd_nudity_classifier.json --attacker.attack_idx $i --logger.name attack_idx_$i```

where ```i``` is from ```[0,142)```

### Evaluation

For ```nudity/violence/illegal```:

```python scripts/analysis/check_asr.py --root-no-attack $path_to_no_attack_results --root $path_to_${P4D|UnlearnDiff}_results ```

For ```style```:

```python scripts/analysis/style_analysis.py --root $path_to_${P4D|UnlearnDiff}_results --top_k {1|3}```


<p><b>Result: JPA on online services</b></p>
<p>Visualization results generated by JPA in NSFW concept under four online T2I services, (texts in red and black respectively represent the adversarial prompts from \textcolor{red}{JPA} and the original prompts from I2P dataset).</p>
<table align="center">
  <tr>
    <td align="center"> 
      <embed src="https://github.com/mjc-ma/JPA/blob/main/imgs/online.pdf" width="1000" height="600" />
      <br>
      <div align="center"><b>Figure 2:</b> Unsafe content generated by JPA on online services.</div>
    </td>
  </tr>
</table>

<p><b>Our key insight comes from: The general concepts can be gradually rendered by the concept embedding.</b></p>
<p>In this figure, we demonstrate the controllable general concepts rendering process.</p>

<!-- First image -->
<table align="center">
  <tr>
    <td align="center"> 
      <embed src="https://github.com/mjc-ma/JPA/blob/main/imgs/guide_name.pdf" width="1000" height="600" />
      <br>
      <div align="center"><b>Figure 3:</b> Concepts pairs of the general concepts.</div>
    </td>
  </tr>
</table>

<!-- Second image -->
<table align="center">
  <tr>
    <td align="center"> 
      <embed src="https://github.com/mjc-ma/JPA/blob/main/imgs/process.pdf" width="1000" height="600" />
      <br>
      <div align="center"><b>Figure 4:</b> Visualization of the concept rendering process showing step-by-step progression.</div>
    </td>
  </tr>
</table>

### Citation

```
@article{ma2024jailbreaking,
  title={Jailbreaking prompt attack: A controllable adversarial attack against diffusion models},
  author={Ma, Jiachen and Cao, Anda and Xiao, Zhiqing and Li, Yijiang and Zhang, Jie and Ye, Chao and Zhao, Junbo},
  journal={arXiv preprint arXiv:2404.02928},
  year={2024}
}
```

